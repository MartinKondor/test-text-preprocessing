{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwl4mTDz5RZi",
        "outputId": "6988d5e1-23e6-44dd-8f35-ea51a31811f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are going to use only the titles from the database\n",
            "[o] X.shape = (6334,)\n",
            "[o] Y.shape = (6334, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords_set = list(set(stopwords.words('english')))\n",
        "\n",
        "df = pd.read_csv(\"data.csv\", sep=\";\")\n",
        "\n",
        "X = df[\"title\"].values\n",
        "Y = df[\"label\"].values.reshape(-1, 1)\n",
        "\n",
        "print(\"We are going to use only the titles from the database\")\n",
        "print(\"[o] X.shape =\", X.shape)\n",
        "print(\"[o] Y.shape =\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2geTdD4E5RZk",
        "outputId": "865e81f8-f3d5-4fe6-b41f-81d98a083dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[o] The longest word is 289 characters long\n"
          ]
        }
      ],
      "source": [
        "maxlen = max([len(x) for x in X])\n",
        "print(\"[o] The longest word is\", maxlen, \"characters long\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIS3e-8-5RZk",
        "outputId": "4034ba63-a046-41bc-c5e4-4fb580f7e12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 289, 578)          3661052   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 288, 256)          296192    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,089,341\n",
            "Trainable params: 4,089,341\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "init_model = lambda _vocab_size, _maxlen: keras.Sequential([\n",
        "    layers.Embedding(input_dim=_vocab_size, output_dim=2*_maxlen, input_length=_maxlen),\n",
        "    layers.Conv1D(256, kernel_size=2, activation=\"relu\"),\n",
        "    layers.GlobalMaxPool1D(),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model = init_model(X.shape[0], maxlen)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwOmHIOf5RZl",
        "outputId": "8d749334-6d6c-491d-e705-93a69537f009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[o] Results for <function tokenization at 0x7f7594687200>:\n",
            "\t[i] Size of X: (6334, 289)\n",
            "\t[i] Max length from X: 289\n",
            "\t[i] Number of DL params: 9274579\n",
            "Epoch 1/15\n",
            "161/161 [==============================] - 71s 431ms/step - loss: 0.4818 - accuracy: 0.7573 - val_loss: 0.3732 - val_accuracy: 0.8491\n",
            "Epoch 2/15\n",
            "161/161 [==============================] - 66s 410ms/step - loss: 0.1415 - accuracy: 0.9515 - val_loss: 0.4266 - val_accuracy: 0.8404\n",
            "Epoch 3/15\n",
            "161/161 [==============================] - 67s 415ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.6035 - val_accuracy: 0.8526\n",
            "[o] [<function tokenization at 0x7f7594687200>] \t acc = 0.8533123135566711\n",
            "\n",
            "[o] Results for <function tokenization_with_prep at 0x7f75946873b0>:\n",
            "\t[i] Size of X: (6334, 289)\n",
            "\t[i] Max length from X: 289\n",
            "\t[i] Number of DL params: 7204183\n",
            "Epoch 1/15\n",
            "161/161 [==============================] - 63s 390ms/step - loss: 0.5281 - accuracy: 0.7236 - val_loss: 0.4598 - val_accuracy: 0.7877\n",
            "Epoch 2/15\n",
            "161/161 [==============================] - 64s 401ms/step - loss: 0.1977 - accuracy: 0.9263 - val_loss: 0.5196 - val_accuracy: 0.7877\n",
            "Epoch 3/15\n",
            "161/161 [==============================] - 62s 388ms/step - loss: 0.0300 - accuracy: 0.9922 - val_loss: 0.7430 - val_accuracy: 0.7772\n",
            "[o] [<function tokenization_with_prep at 0x7f75946873b0>] \t acc = 0.8217665553092957\n",
            "\n",
            "[o] Results for <function tokenization_without_stopwords at 0x7f7594687680>:\n",
            "\t[i] Size of X: (6334, 289)\n",
            "\t[i] Max length from X: 289\n",
            "\t[i] Number of DL params: 7163723\n",
            "Epoch 1/15\n",
            "161/161 [==============================] - 61s 376ms/step - loss: 0.5389 - accuracy: 0.7156 - val_loss: 0.4360 - val_accuracy: 0.7947\n",
            "Epoch 2/15\n",
            "161/161 [==============================] - 61s 381ms/step - loss: 0.2006 - accuracy: 0.9275 - val_loss: 0.4912 - val_accuracy: 0.7912\n",
            "Epoch 3/15\n",
            "161/161 [==============================] - 60s 374ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.7123 - val_accuracy: 0.7789\n",
            "[o] [<function tokenization_without_stopwords at 0x7f7594687680>] \t acc = 0.7917981147766113\n",
            "\n",
            "[o] Results for <function prep_text_with_regex at 0x7f7594687950>:\n",
            "\t[i] Size of X: (6334, 289)\n",
            "\t[i] Max length from X: 289\n",
            "\t[i] Number of DL params: 6377065\n",
            "Epoch 1/15\n",
            "161/161 [==============================] - 61s 377ms/step - loss: 0.5380 - accuracy: 0.7185 - val_loss: 0.4751 - val_accuracy: 0.7789\n",
            "Epoch 2/15\n",
            "161/161 [==============================] - 60s 370ms/step - loss: 0.2193 - accuracy: 0.9187 - val_loss: 0.5174 - val_accuracy: 0.7702\n",
            "Epoch 3/15\n",
            "161/161 [==============================] - 61s 377ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 0.7071 - val_accuracy: 0.7772\n",
            "[o] [<function prep_text_with_regex at 0x7f7594687950>] \t acc = 0.7760252356529236\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from test import tokenization, tokenization_with_prep, tokenization_without_stopwords, prep_text_with_regex\n",
        "\n",
        "\n",
        "prep_methods = [\n",
        "    tokenization,\n",
        "    tokenization_with_prep,\n",
        "    tokenization_without_stopwords,\n",
        "    prep_text_with_regex\n",
        "]\n",
        "\n",
        "for prep_method in prep_methods:\n",
        "    print(f\"[o] Results for {prep_method}:\")\n",
        "\n",
        "    seed = 219\n",
        "    epoch = 15\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    maxlen = max([len(x) for x in X])\n",
        "    new_X = prep_method(X)\n",
        "    new_X = pad_sequences(new_X, padding=\"post\", maxlen=maxlen)\n",
        "    model = init_model(np.max(new_X)+1, maxlen)\n",
        "\n",
        "    print(\"\\t[i] Size of X:\", new_X.shape)\n",
        "    print(\"\\t[i] Max length from X:\", maxlen)\n",
        "    print(\"\\t[i] Number of DL params:\", model.count_params())\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(new_X, Y, test_size=0.1, shuffle=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)\n",
        "\n",
        "    model.compile(metrics=[\"accuracy\"], optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=2,\n",
        "        restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epoch,\n",
        "        verbose=True,\n",
        "        validation_data=(X_val, y_val,),\n",
        "        #validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "        \n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=False)\n",
        "    print(f\"[o] [{prep_method}] \\t acc =\", acc)\n",
        "    print()\n",
        "\n",
        "    del X_train, X_test, y_train, y_test, X_val, y_val, model, history"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tfn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a6b531d05f346ef7d3dcb3c4294551e0bb2bf64a88a8e28bd740789d58209f53"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
